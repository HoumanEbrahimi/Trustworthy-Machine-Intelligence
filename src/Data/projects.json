[
    {
      "name": "Ethics in AI Podcast",
      "imagePath": "https://ethical-principles-in-ai.github.io/static/media/mic.8a60d7a28cd4a4a8f401.png",
      "description": "There are many subtopics within ethics in AI and data science. The goal of producing monthly podcasts is to explore and analyze relevant and interesting topics in an engaging way that is accessible to the general public. This project gives autonomy to pick which topics from ethics in AI to explore, while also serving as practice for reading academic literature (amongst other sources) and communicating sometimes technical/difficult concepts clearly to a wide audience."
    },
    {
      "name": "Sentiment Analysis of Tweets",
      "imagePath": "https://ethical-principles-in-ai.github.io/static/media/Twitter-logo.svg.04f7a024bcf8dae9a657.png",
      "description": "Hateful posts have become a regular phenomena, so moderation is needed, however at such high volumes it is hard to contain. In this project, you will work with a team over the fall and winter semester to design a solution to containing harmful posts. Do so by creating a sentiment analysis model to highlight stigmatic posts to users before they post the text."
    },
    {
      "name": "Debiasing NLP Models",
      "imagePath": "https://ethical-principles-in-ai.github.io/static/media/Debiasing_model.a86e4f01788ac3567946.png",
      "description": "Word embeddings are used widely in Natural Language Processing (NLP) tasks. They have many applications, such as resume filtering or document ranking in word search. Unfortunately, word embedding models have been shown to amplify biases found in the datasets they were trained on. This exacerbates the negative stereotypes found in society, which is a direct violation of the principles of responsible technology and ethical AI. There is a need to reduce and/or eliminate bias in word embeddings so that algorithms can better serve society and align with the public interest. Over the course of the fall and winter semester, collaborate with a team to design a debiased word embedding model and demonstrate your work in a website or through a video."
    },
    {
      "name": "Past Initiatives - Deep Learning with Differential Privacy",
      "imagePath": "https://ethical-principles-in-ai.github.io/static/media/privacy.92eaf5e0c9f06acbfa41.png",
      "description": "Training high quality machine learning models requires large, representative datasets, which may be crowdsourced and contain sensitive information. Even in instances when sensitive information is not explicitly used to train a model, patterns can be extracted and re-identify personal identification about an individual. Models should be designed to protect private information in these datasets. In this project, different algorithmic techniques for learning will be implemented on medical image datasets and an analysis of privacy costs within the framework of differential privacy will be completed to evaluate the merits and room for improvement of different techniques. This project deliverable will be a research paper summarizing the results found throughout the fall and winter semester."
    },
    {
        "name": "Past Initiatives - Paper Reading Group",
        "imagePath": "https://ethical-principles-in-ai.github.io/static/media/paper_reading.d27cf5f3784a3b621625.jpg",
        "description": "We meet bi-weekly during the semester to discuss academic papers in the field of Ethical AI. Participation is open to all and guests are always welcome! Meetings will be held in the EPAI discord voice channel paper-reading-meeting-room"
      
    },
    {
        "name": "Past Project - Bias in Facial Recognition Systems",
        "imagePath": "https://ethical-principles-in-ai.github.io/static/media/facial-recognition.5374780028ee7f44127e.png",
        "description": "Facial recognition systems can be found almost anywhere, from police departments to the face-lock feature in your phone. However, these systems can be biased, often in ways that reflect current social inequalities. This applied project explores bias in facial recognition systems, while also serving as an introduction to writing machine learning code and reading ML literature for beginners."
      
    },
    {
        "name": "Past Initiatives - AIHacks4Good",
        "imagePath": "https://ethical-principles-in-ai.github.io/static/media/AIHacks4Good_Logo.635528102bb8f6b2041e.png",
        "description": "This was a virtual hackathon ran in October 2022, with over 160 participants. The event was sponsored by MLH, IBM, and Intel, and included over 1000 dollars in cash prizes!"
      
    }
    
    
  ]